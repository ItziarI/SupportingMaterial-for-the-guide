- **Title: Working example 2**
- **Output: html_document**
- **Reference: A guide to test association between Polygenic Risk Scores and psychological and psychiatric traits: practical examples**
- **Authors: Itziar Irigoien, Patricia Mas, Sergi Papiol, Neus Barrantes-Vidal, Araceli Rosa, and Concepción Arenas**


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
source("Functions.R")
library(ggplot2)
library(car)
library(multcomp)
```

## Working example 2

**In this example we simulate 10 PRSs, and a continuous trait, with gender, clinical diagnosis (with 2 categories), age, and two Principal Components as covariates.**

- **data reading**
```{r}
dat <- read.table("WExample2.csv", header=TRUE, sep=";", dec=",")
names(dat) #
```

- **do not forget to declare the categorical variables as factors**
```{r}
dat$Sex <- as.factor(dat$Sex)
dat$Diagnostic <- as.factor(dat$Diagnostic)
```


## 1.	What full model should be considered?

- **First, given a particular PRS (named PRS.i), consider all the possible full models:**
- **FMWI : Trait versus PRS.i + Sex + Diagnostic + Age + PC1 + PC2**
- **FMSex: Trait versus PRS.i + Sex + PRS.i · Sex + Diagnostic + Age + PC1 + PC2**
- **FMDiagnostic: Trait versus PRS.i + Sex + Diagnostic + PRS.i  · Diagnostic + Age + PC1 + PC2**
- **FMSex/Diagnostic: Trait versus PRS.i + Sex + PRS.i · Sex + Diagnostic + PRS.i · Diagnostic + Age + PC1 + PC2**

## 2. How to make a PRS ranking to find the important ones?
- **As is described in the paper, for each model, calculate the coefficient of determination $R^2$ and calculate the sum: $S =  R^2_{WI} +  R^2_{Sex} +  R^2_{Diagnostic} +  R^2_{Sex*Diagnostic}$.** 

- **According to S, list the PRSs in decreasing order.**
```{r}
out <- orderR2(dat, yname="Trait", prsname = "PRS.")
head(out)
mainfilename <- "WExample2"
filename <- paste0(mainfilename, "_Ordered_PRS.csv")
write.csv2(out,file=filename)
```

- **Plot the sum of coefficients of determination $S_{R^2}$. Lines: in blue the median; in black the mean.**
```{r}
out <- data.frame(out) 
n <- dim(out)[1]
select <- grep("Model", names(out), value=FALSE)
out$effect <- out$Sum
sds <- apply(out[, select], 1, sd)
out$lower <- out$effect - sds
out$upper <- out$effect + sds
out$rank <- n:1


ggplot(data=out, aes(y=rank, x=effect, xmin=lower, xmax=upper)) +
  geom_point() +
  geom_errorbarh(height=.1) +
  scale_y_continuous(name=NULL, breaks= n:1, labels=row.names(out), position="right") +
  labs(title='', x='Sum R^2', y = 'PRS') +
  geom_vline(xintercept=mean(out$effect), color='black', linetype='dashed') +
  geom_vline(xintercept=median(out$effect), color='blue', linetype='dashed') +
  theme_minimal()

```

  **According to the obtained results, first PRS.5 is selected to analyse its association with the Trait.**

## 3. Which model, of all the possible ones, should be used?

**The following figure represents the scatter plot of Trait versus PRS.5 separated by Sex and Diagnostic groups.**
```{r}
ggplot(dat, aes(x=PRS.5, y=Trait)) +
  geom_point() +
  geom_smooth(method=lm, se=FALSE)+
  facet_grid(Sex ~ Diagnostic, labeller=label_both)
# Candidate FM Trait ~ PRS + Sex + Diagnostic + PRS + PRS*Diagnostic + PC1 +PC2
```

**The plots suggest that the interaction between the PRS.5 and the diagnostic is relevant. Thus, we set the full model candidate (FM): $Trait \sim PRS + Sex + Diagnostic + Sex + PRS \cdot Diagnostic + PC1 +PC2$.**


## 4.	For a continuous trait, what steps should be followed for a correct analysis?
- **4.1.  How is the candidate model validated?**

- **First, we validate the normality of the errors and the constant variance conditions (see the figures and the results of Shapiro test and Levene test)**
```{r}
#model
FM <- lm(Trait ~ PRS.5*Diagnostic + Sex + Age + PC1 + PC2, data=dat)
#qq-plot for normality 
plot(FM,2)   
```

  **Lack of normality of residuals is suggested and this is supported by Shapiro’s test**

```{r}
#Shapiro-Wilk test
shapiro.test(FM$residuals)
```

```{r}
#plot for variances
d <- fortify(FM)
ggplot(d,aes(x=.fitted, y=.stdresid, colour=Diagnostic)) + geom_point() + geom_hline(yintercept=0, col="red")+
  facet_wrap(.~Diagnostic)
```

```{r}
#Levene's test
leveneTest(.stdresid ~ Diagnostic, data=d)
```

- **The figure does not show problems with the residuals, although it can be seen that for Diagnostic group 1 their variability increases as the fitted values do so, suggesting possible problems with the homogeneity of variances. However, Levene’s test does not indicate evidence against homoscedasticity, neither a trend is observed that could indicate a lack of linearity.**

- **4.2. What can be done if any validation condition fails?**

  **We have two approaches to assess the possible association with PRS.5 and the Trait: try a transformation of the trait or perform a permutation test**

- **First, we try a transformation. Given the shape of the density of residuals given by the next figure, the logarithmic transformation seems adequate to achieve normality.**
```{r}
#Histogram of the residuals
hist(FM$residuals)
```



```{r}
dat$logTrait <- log(dat$Trait)
FM <- lm(logTrait ~ PRS.5*Diagnostic + Sex + Age + PC1 + PC2, data=dat)
#qq-plot for normality 
plot(FM,2)
```
```{r}
#Shapiro-Wilk test
shapiro.test(FM$residuals)
```

- **Thus, it is suggested the transformation offered a solution for the lack of normality. Furthermore,**
```{r}
#plot for variances
d <- fortify(FM)
ggplot(d,aes(x=.fitted, y=.stdresid, colour=Diagnostic)) + geom_point() + geom_hline(yintercept=0, col="red")+
  facet_wrap(.~Diagnostic)
```

```{r}
#Levene's test
leveneTest(.stdresid ~ Diagnostic, data=d)
```

   - **It does not indicate evidence against homoscedasticity, neither a trend is observed that could indicate a lack of linearity.**

   - **Then, the model we build is given by:**


```{r}
summary(FM)
```

- **The results show that PRS.5 is related with the log(Trait) in the following way:**
  + $\widehat{log(Trait)} = 2.585 + 0.00089\times PRS.5 + 0.041\times Sex - 0.0006\times Age + 0.197\times PC1 - 0.0596\times PC2$, if Diagnostic = 0;
  + $\widehat{log(Trait)} = (2.585-20.052) + (0.00089-0.26068)\times PRS.5 +  0.041\times Sex + - 0.0006\times Age  + 0.197\times PC1 - 0.0596\times PC2$, if Diagnostic = 1;
  
**where Sex takes values 0 or 1, depending on whether the individual under study is male or female, affecting only the value of the intercept.**

- **If the objective is to evaluate the possible association between Trait and PRS.5, it can be interesting to check whether the respective PRS.4 coefficients under each Diagnostic group are considerable or not.**
```{r}
summary(glht(FM, "PRS.5 = 0"))
summary(glht(FM, "PRS.5  + PRS.5:Diagnostic1 = 0"))
```

- **This means that for Diagnostic 1 the association is significant ($p$-value= 0.004487) and negative and if PRS increases in one unit while keeping the other predictors constant, the change in the Trait is obtained multiplying by coeff = exp(-0.25979) = 0.771; therefore it will decrease. For Diagnostic 0 there is no significant association, and if PRS increases in one unit while keeping the other predictors constant, the expected change in the Trait is obtained multiplying by coeff = exp(0.00089) = 1.001; thus no change is expected. The ratio $\widehat{log(Trait)}|PRS.5 = 1/\widehat{log(Trait)}|PRS.5=0 = exp(-0.25979)=0.771 < 1$, thus, gives a mean decrease of about 22.9\%, for any given value (PRS.5= prs value).**




- **On the other hand, with the permutation approach:**
```{r}
NM <- lm(Trait ~ Diagnostic + Sex + Age + PC1 + PC2, data=dat)
FM <- lm(Trait ~ PRS.5*Diagnostic + Sex + Age + PC1 + PC2, data=dat)
outperm <- dR2(NullModel=NM, FullModel=FM, B=1000, seed=165)
outperm
```
- **We observe an increase of 0.108 in the coefficient of determination when the PRS.5 is included in the model and the permutation test indicates it is significant.**


- **Last step: We move to the next PRS.**

