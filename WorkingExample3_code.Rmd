---
title: "WORKING EXAMPLE 3"
subtitle:  "In: A guide to test association between Polygenic Risk Scores and psychological and psychiatric traits: practical examples"
author:  
  - "Itziar Irigoien, Patricia Mas-Bermejo, Sergi Papiol, Neus Barrantes-Vidal,"
  - "Araceli Rosa, and Concepción Arenas"
output:
  pdf_document:
    keep_tex: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
source("Functions.R")
library(ggplot2)
library(car)
library(MASS)
```


## Working flow and code

In this example we simulate 5 PRSs, and a continuous trait, with sex, clinical diagnosis (with 2 categories), age, and two Principal Components as covariates.

- data reading
```{r}
dat <- read.table("WExample3.csv", header=TRUE, sep=";", dec=",")
names(dat) #
```

\bigskip

- do not forget to declare the categorical variables as factors
```{r}
dat$Sex <- as.factor(dat$Sex)
dat$Diagnostic <- as.factor(dat$Diagnostic)
```

## 1.	What full model should be considered?

First, given a particular PRS (named PRS.i), consider all the possible full models:

- FM$_{WI}$ : Trait versus PRS.i + Sex + Diagnostic + Age + PC1 + PC2
- FM$_{Sex}$: Trait versus PRS.i + Sex + PRS.i · Sex + Diagnostic + Age + PC1 + PC2
- FM$_{Diagnostic}$: Trait versus PRS.i + Sex + Diagnostic +    PRS.i  · Diagnostic + Age + PC1 + PC2
- FM${Sex/Diagnostic}$: Trait versus PRS.i + Sex + PRS.i · Sex + Diagnostic + PRS.i · Diagnostic + Age + PC1 + PC2

## 2. How to make a PRS ranking to find the important ones?

As is described in the paper, for each model, calculate the coefficient of determination $R^2$ and calculate the sum: $S =  R^2_{WI} +  R^2_{Sex} +  R^2_{Diagnostic} +  R^2_{Sex \cdot Diagnostic}$. 

According to S, list the PRSs in decreasing order:
```{r}
out <- orderR2(dat, yname="Trait", prsname = "PRS.")
head(out)
write.csv2(out,file="WExample1_Ordered_PRS.csv")
```

Plot the sum of coefficients of determination $S_{R^2}$. Lines: in blue the median; in black the mean.
```{r}
out <- data.frame(out) 
nPRS <- dim(out)[1]
select <- grep("Model", names(out), value=FALSE)
out$effect <- out$Sum
sds <- apply(out[, select], 1, sd)
out$lower <- out$effect - sds
out$upper <- out$effect + sds
out$rank <- nPRS:1

n <- dim(out)[1]
ggplot(data=out, aes(y=rank, x=effect, xmin=lower, xmax=upper)) +
  geom_point() +
  geom_errorbarh(height=.1) +
  scale_y_continuous(name=NULL, breaks= n:1, labels=row.names(out), position="right") +
  labs(title='', x='Sum R^2', y = 'PRS') +
  geom_vline(xintercept=mean(out$effect), color='black', linetype='dashed') +
  geom_vline(xintercept=median(out$effect), color='blue', linetype='dashed') +
  theme_minimal()

```

According to the obtained results, first PRS.1 is selected to analyze its association with the Trait.

## 3. Which model, of all the possible ones, should be used?

The following figure represents the scatter plot of Trait versus PRS.1 separated by Sex and Diagnostic groups.
```{r}
ggplot(dat, aes(x=PRS.1, y=Trait)) +
  geom_point() +
  geom_smooth(method=lm, se=FALSE)+
  facet_grid(Sex ~ Diagnostic, labeller=label_both)
```

The plots suggest that the interaction between the PRS.1 and sex is relevant. Thus, we set the full model candidate (FM): $Trait \sim PRS + Sex + Diagnostic + PRS\cdot Sex + PC1 +PC2$.

### 4.	For a continuous trait, what steps should be followed for a correct analysis?

- **4.1.  How is the candidate model validated?**

First, we validate the normality of the errors and the constant variance conditions (see the figures and the results of Shapiro test and Levene test).
```{r}
#model
FM <- lm(Trait ~ PRS.1*Sex + Diagnostic + Age + PC1 + PC2, data=dat)
#qq-plot for normality 
plot(FM,2)   
```

```{r}
#Shapiro-Wilk test
shapiro.test(FM$residuals)
```

```{r}
#plot for variances
d <- fortify(FM)
ggplot(d,aes(x=.fitted, y=.stdresid, colour=Sex)) + 
  geom_point() + 
  geom_hline(yintercept=0, col="red")+
  facet_wrap(.~Sex)
```

```{r}
#Levene's test
leveneTest(.stdresid ~ Sex, data=d)
```

It seems that homocedasticity does not hold.

- **4.2. What can be done if any validation condition fails?**

We have two approaches to assess the possible association with PRS.1 and the Trait: try a Box-Cox transformation  or perform a weighted permutation test.

First, we try a Box-Cox transformation of the dependent variable:
  - Determine the lambda value.
```{r}
b <- boxcox(FM)
```
```{r}
# Exact lambda
lambda <- b$x[which.max(b$y)]
lambda
```
 - Transform the dependent variable and establish the new model.
```{r}
dat$newTrait <- (dat$Trait ^ lambda - 1) / lambda
FM <- lm(newTrait ~ PRS.1*Sex + Diagnostic + Age + PC1 + PC2, data=dat)
```

- Check the normality and homocedasticity conditions.
```{r}
#Shapiro-Wilk test
shapiro.test(FM$residuals)
```

```{r}
#Levene's test
d <- fortify(FM)
leveneTest(.stdresid ~ Sex, data=d)
```

In this case, the suggested Box-Cox transformation with $\lambda = 0.667$ does not solve the heteroscedasticity problem. For this reason we perform a weighted-permutation test. 


```{r}
NM <- lm(Trait ~ Sex + Diagnostic + Age + PC1+PC2, data=dat)
FM <- lm(Trait ~ PRS.1*Sex + Diagnostic + Age + PC1+PC2, data=dat)
outperm <- dR2(NullModel=NM, FullModel=FM, B=1000, seed=165,  weights=TRUE)
outperm
```

We observe an increase of 0.092 in the coefficient of determination when the PRS.1 is included in the model and the permutation test indicates it is significant.



- **Last step: We move to the next PRS.**

